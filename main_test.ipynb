{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "gross-balloon",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"\")\n",
    "import voice_test.voice_recognition_server as vrs\n",
    "import time\n",
    "\n",
    "import requests\n",
    "import json\n",
    "import base64\n",
    "import os\n",
    "import logging\n",
    "import speech_recognition as sr\n",
    "\n",
    "#object detection from video\n",
    "import numpy as np\n",
    "import os\n",
    "import six.moves.urllib as urllib\n",
    "import tarfile\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import backend\n",
    "import zipfile\n",
    "from collections import defaultdict\n",
    "from io import StringIO\n",
    "\n",
    "sys.path.append(\"/home/ys/train_model/models/research/object_detection\")\n",
    "sys.path.append(\"/home/ys/discovery_cup/voice_snowboy/test\")\n",
    "from utils import ops as utils_ops\n",
    "if tf.__version__ < '1.4.0':\n",
    "  raise ImportError('Please upgrade your tensorflow installation to v1.4.* or later!')\n",
    "\n",
    "from utils import label_map_util\n",
    "from utils import visualization_utils as vis_util"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "excellent-shareware",
   "metadata": {},
   "outputs": [],
   "source": [
    "rec_words = ['香蕉','苹果','人','手机','衣服']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "pursuant-disposal",
   "metadata": {},
   "outputs": [],
   "source": [
    "def callback_start_wav2word():\n",
    "    \n",
    "    time.sleep(0.2)\n",
    "    print(\"start!!!\")\n",
    "    key_word = wav2str()\n",
    "    #key_word = '香蕉'\n",
    "    print(key_word)\n",
    "    key_location = find_obj_in_camera(key_word)\n",
    "    print(key_location)\n",
    "    lr, lr_angel, tb = cal_location(key_location)\n",
    "    print(lr, lr_angle, tb)\n",
    "    str2voice_play(key_word, lr, lr_angle, tb)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "instant-causing",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal_locationg(key_location):\n",
    "    center_x = (key_location[0] + key_location[2]) / 2.0\n",
    "    center_y = (key_location[1] + key_location[3]) / 2.0\n",
    "    lr = None\n",
    "    lr_angle = 0\n",
    "    tb = None\n",
    "    if center_x <= 0.5:\n",
    "        lr = '偏左'\n",
    "        lr_angle = (0.5 - center_x) / 0.5 * 90\n",
    "    else:\n",
    "        lr = '偏右'\n",
    "        lr_angle = (center_x - 0.5) / 0.5 * 90\n",
    "    \n",
    "    if center_y < 0.4:\n",
    "        tb = '偏上'\n",
    "    elif center_y >= 0.4 and center_y <= 0.6:\n",
    "        tb = '居中'\n",
    "    else center_y >0.6:\n",
    "        tb = '偏下'\n",
    "    \n",
    "    return lr, lr_angle, tb\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "perceived-subscriber",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyttsx3\n",
    "\n",
    "def str2voice_play(key_word, lr, lr_angle, tb):\n",
    "    # 创建对象\n",
    "    engine = pyttsx3.init()\n",
    "    # 获取当前语音速率\n",
    "    rate = engine.getProperty('rate')\n",
    "    print(f'语音速率：{rate}')\n",
    "    # 设置新的语音速率\n",
    "    engine.setProperty('rate', 200)\n",
    "    # 获取当前语音音量\n",
    "    volume = engine.getProperty('volume')\n",
    "    print(f'语音音量：{volume}')\n",
    "    # 设置新的语音音量，音量最小为 0，最大为 1\n",
    "    engine.setProperty('volume', 1.0)\n",
    "    # 获取当前语音声音的详细信息\n",
    "    voices = engine.getProperty('voices')\n",
    "    #print(f'语音声音详细信息：{voices}')\n",
    "    # 设置当前语音声音为女性，当前声音不能读中文\n",
    "    engine.setProperty('voice', 'zh')\n",
    "    # 设置当前语音声音为男性，当前声音可以读中文\n",
    "    #engine.setProperty('voice', voices[0].id)\n",
    "    # 获取当前语音声音\n",
    "    voice = engine.getProperty('voice')\n",
    "    print(f'语音声音：{voice}')\n",
    "    # 语音文本\n",
    "    #path = 'test.txt'\n",
    "    #with open(path, encoding='utf-8') as f_name:\n",
    "    #    words = str(f_name.readlines()).replace(r'\\n', '')\n",
    "    # 将语音文本说出来\n",
    "    words = key_word + \"在设备\" + lr + str(lr_angle) + \"度角并且\" + tb + \"位置\"\n",
    "    engine.say(words)\n",
    "    engine.runAndWait()\n",
    "    engine.stop()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "beginning-flour",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"access_token\":\"24.d0088d80ec54862b62d2f13aa2baaf07.2592000.1616640930.282335-23652211\",\"session_key\":\"9mzdX+rSN0bkpcuTJEkbF2l5EEBmCw0jmk\\/ZQ+WNsyr8l6tn4CTm+yUmud1eSn77NXL+mr8lRUYGem0EEwwevwZcH5Ki3A==\",\"scope\":\"audio_voice_assistant_get brain_enhanced_asr audio_tts_post brain_speech_realtime public brain_all_scope picchain_test_picchain_api_scope brain_asr_async wise_adapt lebo_resource_base lightservice_public hetu_basic lightcms_map_poi kaidian_kaidian ApsMisTest_Test\\u6743\\u9650 vis-classify_flower lpq_\\u5f00\\u653e cop_helloScope ApsMis_fangdi_permission smartapp_snsapi_base smartapp_mapp_dev_manage iop_autocar oauth_tp_app smartapp_smart_game_openapi oauth_sessionkey smartapp_swanid_verify smartapp_opensource_openapi smartapp_opensource_recapi fake_face_detect_\\u5f00\\u653eScope vis-ocr_\\u865a\\u62df\\u4eba\\u7269\\u52a9\\u7406 idl-video_\\u865a\\u62df\\u4eba\\u7269\\u52a9\\u7406 smartapp_component smartapp_search_plugin\",\"refresh_token\":\"25.88d7c623d8c0cb31db3fc457503f4afd.315360000.1929408930.282335-23652211\",\"session_secret\":\"e0848889756cc5ca909da0f1e18ac9e4\",\"expires_in\":2592000}\n",
      "\n",
      "{'access_token': '24.d0088d80ec54862b62d2f13aa2baaf07.2592000.1616640930.282335-23652211', 'session_key': '9mzdX+rSN0bkpcuTJEkbF2l5EEBmCw0jmk/ZQ+WNsyr8l6tn4CTm+yUmud1eSn77NXL+mr8lRUYGem0EEwwevwZcH5Ki3A==', 'scope': 'audio_voice_assistant_get brain_enhanced_asr audio_tts_post brain_speech_realtime public brain_all_scope picchain_test_picchain_api_scope brain_asr_async wise_adapt lebo_resource_base lightservice_public hetu_basic lightcms_map_poi kaidian_kaidian ApsMisTest_Test权限 vis-classify_flower lpq_开放 cop_helloScope ApsMis_fangdi_permission smartapp_snsapi_base smartapp_mapp_dev_manage iop_autocar oauth_tp_app smartapp_smart_game_openapi oauth_sessionkey smartapp_swanid_verify smartapp_opensource_openapi smartapp_opensource_recapi fake_face_detect_开放Scope vis-ocr_虚拟人物助理 idl-video_虚拟人物助理 smartapp_component smartapp_search_plugin', 'refresh_token': '25.88d7c623d8c0cb31db3fc457503f4afd.315360000.1929408930.282335-23652211', 'session_secret': 'e0848889756cc5ca909da0f1e18ac9e4', 'expires_in': 2592000}\n",
      "audio_voice_assistant_get\n",
      "SUCCESS WITH TOKEN: 24.d0088d80ec54862b62d2f13aa2baaf07.2592000.1616640930.282335-23652211  EXPIRES IN SECONDS: 2592000\n"
     ]
    }
   ],
   "source": [
    "token = vrs.fetch_token()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "annual-throw",
   "metadata": {},
   "outputs": [],
   "source": [
    "def wav2str():\n",
    "    #### 录音并保存，静音时停止\n",
    "    logging.basicConfig(level=logging.INFO)\n",
    "    AUDIO_FILE = \"./voice_rec.wav\"     # 只支持 pcm/wav/amr 格式，极速版额外支持m4a 格式\n",
    "    while True:\n",
    "        r = sr.Recognizer()\n",
    "        #启用麦克风\n",
    "        mic = sr.Microphone()\n",
    "        logging.info('录音中...')\n",
    "        print(\"录音中\")\n",
    "        with mic as source:\n",
    "            #降噪\n",
    "            r.adjust_for_ambient_noise(source)\n",
    "            audio = r.listen(source)\n",
    "        with open(AUDIO_FILE, \"wb\") as v:\n",
    "            #将麦克风录到的声音保存到voice_rec.wav文件中\n",
    "            v.write(audio.get_wav_data(convert_rate=16000))\n",
    "        logging.info('录音结束，识别中...')\n",
    "        result_str = vrs.pull_wav(AUDIO_FILE, token)\n",
    "        result = json.loads(result_str)\n",
    "        print(result['result'])\n",
    "        \n",
    "        for key_word in rec_words:\n",
    "            if key_word in result['result'][0]:\n",
    "                print('识别到：',key_word)\n",
    "                print(result_str)\n",
    "                print(result['result'])\n",
    "                return key_word\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "welsh-spider",
   "metadata": {},
   "outputs": [],
   "source": [
    "# What model to download.\n",
    "MODEL_NAME = 'object_detection_ipython/ssd_mobilenet_v1_coco_2017_11_17'\n",
    "\n",
    "# Path to frozen detection graph. This is the actual model that is used for the object detection.\n",
    "PATH_TO_CKPT = MODEL_NAME + '/frozen_inference_graph.pb'\n",
    "\n",
    "# List of the strings that is used to add correct label for each box.\n",
    "PATH_TO_LABELS = os.path.join('/home/ys/train_model/models/research/object_detection/data', 'mscoco_label_map.pbtxt')\n",
    "\n",
    "NUM_CLASSES = 90\n",
    "\n",
    "detection_graph = tf.Graph()\n",
    "with detection_graph.as_default():\n",
    "  #od_graph_def = tf.GraphDef()\n",
    "  od_graph_def = tf.compat.v1.GraphDef()\n",
    "  with tf.io.gfile.GFile(PATH_TO_CKPT, 'rb') as fid:\n",
    "    serialized_graph = fid.read()\n",
    "    od_graph_def.ParseFromString(serialized_graph)\n",
    "    tf.import_graph_def(od_graph_def, name='')\n",
    "    \n",
    "label_map = label_map_util.load_labelmap(PATH_TO_LABELS)\n",
    "categories = label_map_util.convert_label_map_to_categories(label_map, max_num_classes=NUM_CLASSES, use_display_name=True)\n",
    "category_index = label_map_util.create_category_index(categories)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "amber-registrar",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "person\n"
     ]
    }
   ],
   "source": [
    "print(category_index[1]['name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "incredible-subdivision",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import time\n",
    "\n",
    "\n",
    "\n",
    "def find_obj_in_camera(key_word):\n",
    "    cap = cv2.VideoCapture(0)  #### choose camera id by  private computer\n",
    "    cap.set(cv2.CAP_PROP_FRAME_WIDTH, 800)\n",
    "    cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 600)\n",
    "    cap.set(cv2.CAP_PROP_FOURCC, cv2.VideoWriter.fourcc('M', 'J', 'P', 'G'))\n",
    "    \n",
    "    with detection_graph.as_default():\n",
    "        with tf.compat.v1.Session() as sess:\n",
    "\n",
    "            while True:\n",
    "                time_start=time.time()\n",
    "                ret, frame = cap.read()\n",
    "\n",
    "                image_tensor = detection_graph.get_tensor_by_name('image_tensor:0')\n",
    "\n",
    "                boxes = detection_graph.get_tensor_by_name('detection_boxes:0')\n",
    "                # Each score represent how level of confidence for each of the objects.\n",
    "                # Score is shown on the result image, together with the class label.\n",
    "                scores = detection_graph.get_tensor_by_name('detection_scores:0')\n",
    "                classes = detection_graph.get_tensor_by_name('detection_classes:0')\n",
    "                num_detections = detection_graph.get_tensor_by_name('num_detections:0')\n",
    "                # Actual detection.\n",
    "                (num_detections, boxes, scores, classes) = sess.run(\n",
    "                    [num_detections, boxes, scores, classes],\n",
    "                    feed_dict={image_tensor: np.expand_dims(frame, 0)})\n",
    "                # Visualization of the results of a detection.\n",
    "                vis_util.visualize_boxes_and_labels_on_image_array(\n",
    "                    frame, np.squeeze(boxes),\n",
    "                    np.squeeze(classes).astype(np.int32),\n",
    "                    np.squeeze(scores), category_index,\n",
    "                    use_normalized_coordinates=True,\n",
    "                    line_thickness=8)\n",
    "\n",
    "                cv2.imshow('object detection', cv2.resize(frame, (800, 600)))\n",
    "                time_end=time.time()\n",
    "                print('time cost',(time_end-time_start)*1000,'ms')\n",
    "            \n",
    "                Hit_rec = []\n",
    "                for idx, score in enumerate(scores[0]):\n",
    "                    if score >= 0.5:\n",
    "                        cls = int(classes[0][idx])\n",
    "                        print(idx, classes[0][idx])\n",
    "                #    if key_word in category_index[cls]['name']:\n",
    "                        if \"person\" in category_index[cls]['name']:\n",
    "                            Hit_rec.append(boxes[0][cls])\n",
    "                    else:\n",
    "                        break\n",
    "                if Hit_rec is not None:\n",
    "                    print(\"find object\")\n",
    "                    print(Hit_rec)\n",
    "                    \n",
    "                    return(Hit_rec)\n",
    "                       \n",
    "                if cv2.waitKey(25) & 0xFF == ord('q'):\n",
    "                    cv2.destroyAllWindows()\n",
    "                    return()\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "greenhouse-czech",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Listening... Press Ctrl+C to exit\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:snowboy:Keyword 1 detected at time: 2021-02-23 10:55:35\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start!!!\n",
      "录音中\n",
      "Request time cost 0.348691\n",
      "['找到香蕉。']\n",
      "识别到： 香蕉\n",
      "{\"corpus_no\":\"6932287408030087686\",\"err_msg\":\"success.\",\"err_no\":0,\"result\":[\"找到香蕉。\"],\"sn\":\"64875880361614048939\"}\n",
      "\n",
      "['找到香蕉。']\n",
      "香蕉\n",
      "time cost 3510.084629058838 ms\n",
      "0 1.0\n",
      "find object\n",
      "[array([0.25204673, 0.41255012, 0.3106204 , 0.4435539 ], dtype=float32)]\n",
      "[array([0.25204673, 0.41255012, 0.3106204 , 0.4435539 ], dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "import snowboydecoder\n",
    "import signal\n",
    "\n",
    "interrupted = False\n",
    "\n",
    "\n",
    "def signal_handler(signal, frame):\n",
    "    global interrupted\n",
    "    interrupted = True\n",
    "\n",
    "\n",
    "def interrupt_callback():\n",
    "    global interrupted\n",
    "    return interrupted\n",
    "\n",
    "#if len(sys.argv) == 1:\n",
    "#    print(\"Error: need to specify model name\")\n",
    "#    print(\"Usage: python demo.py your.model\")\n",
    "#    sys.exit(-1)\n",
    "\n",
    "#model = sys.argv[1]\n",
    "model = \"/home/ys/discovery_cup/voice_snowboy/test/hotword.pmdl\"\n",
    "# capture SIGINT signal, e.g., Ctrl+C\n",
    "signal.signal(signal.SIGINT, signal_handler)\n",
    "\n",
    "detector = snowboydecoder.HotwordDetector(model, sensitivity=0.5)\n",
    "print('Listening... Press Ctrl+C to exit')\n",
    "\n",
    "# main loop\n",
    "detector.start(detected_callback=callback_start_wav2word,\n",
    "               interrupt_check=interrupt_callback,\n",
    "               sleep_time=0.03)\n",
    "\n",
    "detector.terminate()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "defensive-spectacular",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
